input {
  file {
    path => "/usr/share/logstash/logs/auth.log"  # Update this with the path to your auth.log file
    start_position => "beginning"
    sincedb_path => "/dev/null"  # Disable sincedb to read the file from the start each time
  }
}

filter {
  # Define a grok filter to parse the log lines into structured fields
  grok {
    match => {
      "message" => [
        "%{SYSLOGTIMESTAMP:timestamp} %{SYSLOGHOST:host} CRON\\[%{NUMBER:pid}\\]: %{GREEDYDATA:cron_message}",
        "%{SYSLOGTIMESTAMP:timestamp} %{SYSLOGHOST:host} systemd-logind\\[%{NUMBER:pid}\\]: %{GREEDYDATA:log_message}",
        "%{SYSLOGTIMESTAMP:timestamp} %{SYSLOGHOST:host} %{DATA:service}\\[%{NUMBER:pid}\\]: %{GREEDYDATA:sudo_message}",
        "%{SYSLOGTIMESTAMP:timestamp} %{SYSLOGHOST:host} pkexec\\[%{NUMBER:pid}\\]: %{GREEDYDATA:pkexec_message}"
      ]
    }
  }

  # Parse the timestamp field to the Logstash @timestamp
  date {
    match => ["timestamp", "MMM dd HH:mm:ss"]
    target => "@timestamp"
    timezone => "UTC"
  }

  # Extract user information from the sudo and pkexec messages
  if "sudo_message" in [tags] {
    dissect {
      mapping => {
        "sudo_message" => "%{user}: PWD=%{path}; USER=%{sudo_user}; COMMAND=%{command}"
      }
    }
  }

  if "pkexec_message" in [tags] {
    dissect {
      mapping => {
        "pkexec_message" => "pam_unix(polkit-1:session): session opened for user %{pkexec_user}(uid=%{pkexec_uid}) by (uid=%{by_uid})"
      }
    }
  }

  # Remove the original message field if needed
  mutate {
    remove_field => ["message", "timestamp"]
  }
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]  # Update this with your Elasticsearch host
    index => "auth-log-%{+YYYY.MM.dd}"
  }
  #stdout {
  #  codec => rubydebug  # Print parsed output to the console for debugging
 # }
}


